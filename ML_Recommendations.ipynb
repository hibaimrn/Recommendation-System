{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9213feda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                                  _id        asin  overall  \\\n",
      "0           0  Row(oid='644ead17f66a6378caeef939')  B017O9P72A        1   \n",
      "1           1  Row(oid='644ead17f66a6378caeef944')  B017O9P72A        2   \n",
      "2           2  Row(oid='644ead17f66a6378caeef959')  B017O9P72A        3   \n",
      "3           3  Row(oid='644ead17f66a6378caeef986')  B017O9P72A        1   \n",
      "4           4  Row(oid='644ead17f66a6378caeef9a1')  B017O9P72A        2   \n",
      "\n",
      "                                          reviewText   reviewTime  \\\n",
      "0  The service works with google home, but doesn'...  12 29, 2017   \n",
      "1  I have to tell alexa to tell lifx to do things...  07 24, 2017   \n",
      "2  Null message fixed by logging out!!! Log out a...   01 5, 2017   \n",
      "3  When I try to link this app to the alexa app I...  09 15, 2016   \n",
      "4  Horrible,  absolutely amateur coding without t...  03 10, 2016   \n",
      "\n",
      "       reviewerID                                            summary  \\\n",
      "0   AA4DHYT5YSSIT                                      Does not work   \n",
      "1  A1ZH6WTMUGWCOU                   Commands need to get shorter!!!!   \n",
      "2  A2XD433O61HBZZ                        Log out to fix null message   \n",
      "3  A2ZJTS4QMA52IV                          Error trying to Authorize   \n",
      "4  A2AQ4B1526F3F5  Underwhelming integration and no voice color c...   \n",
      "\n",
      "   unixReviewTime  verified  \n",
      "0      1514505600     False  \n",
      "1      1500854400     False  \n",
      "2      1483574400     False  \n",
      "3      1473897600     False  \n",
      "4      1457568000     False  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data from the CSV file\n",
    "data = pd.read_csv('recommendation_data.csv')\n",
    "\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "076b010a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (900, 10)\n",
      "Testing data shape: (225, 10)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print the shape of the training and testing data to verify the split\n",
    "print(\"Training data shape:\", train_data.shape)\n",
    "print(\"Testing data shape:\", test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73c686b",
   "metadata": {},
   "source": [
    "# 1. Colabarative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efceb6ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating RMSE, MAE of algorithm KNNBasic on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    1.5821  1.5817  1.5625  1.5803  1.5486  1.5710  0.0134  \n",
      "MAE (testset)     1.4162  1.4228  1.3767  1.4003  1.3781  1.3988  0.0189  \n",
      "Fit time          0.02    0.02    0.00    0.02    0.00    0.01    0.01    \n",
      "Test time         0.00    0.00    0.00    0.00    0.00    0.00    0.00    \n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.knns.KNNBasic at 0x21a0d0ab700>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise import Dataset, Reader, KNNBasic\n",
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "# Create a reader object to parse the data\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "\n",
    "# Load the data into the Surprise Dataset format\n",
    "train_dataset = Dataset.load_from_df(train_data[['reviewerID', 'asin', 'overall']], reader)\n",
    "\n",
    "# Define the collaborative filtering algorithm (e.g., KNNBasic)\n",
    "cf_model = KNNBasic()\n",
    "\n",
    "# Perform cross-validation on the training data\n",
    "cross_validate(cf_model, train_dataset, measures=['RMSE', 'MAE'], cv=5, verbose=True)\n",
    "\n",
    "# Train the collaborative filtering model on the entire training data\n",
    "trainset = train_dataset.build_full_trainset()\n",
    "cf_model.fit(trainset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c61406",
   "metadata": {},
   "source": [
    "# 2. Content Based Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e23035d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Item id i.e. asin: B017O9P72A\n",
      "Top 10 recommendations:\n",
      "['B015TJD0Y4' 'B015S1SWLO' 'B015TJD0Y4' 'B00XNQECFM' 'B00U33Q940'\n",
      " 'B00VXS8E8S' 'B015S1SWLO' 'B00VXS8E8S' 'B00VXS8E8S' 'B00VXS8E8S']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "# Create a TF-IDF vectorizer to convert text features into numerical vectors\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Compute TF-IDF vectors for the reviewText column\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(train_data['reviewText'].values.astype('U'))\n",
    "\n",
    "# Compute cosine similarities between all items using the TF-IDF vectors\n",
    "item_similarities = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "# Function to get top N similar items based on cosine similarity\n",
    "def get_similar_items(item_id, top_n=5):\n",
    "    item_index = train_data[train_data['asin'] == item_id].index[0]\n",
    "    similar_indices = item_similarities[item_index].argsort()[::-1][1:top_n+1]\n",
    "    similar_items = train_data.iloc[similar_indices]['asin'].values\n",
    "    return similar_items\n",
    "\n",
    "# Example usage: Get top 5 similar items for a given item ID\n",
    "item_id=input('Enter Item id i.e. asin: ')\n",
    "#item_id = 'B017O9P72A'\n",
    "similar_items = get_similar_items(item_id, top_n=10)\n",
    "print(\"Top 10 recommendations:\")\n",
    "print(similar_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6793ca",
   "metadata": {},
   "source": [
    "# 3. Matrix Factoerization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "524286af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    1.5909  1.6429  1.4797  1.4000  1.4938  1.5215  0.0858  \n",
      "MAE (testset)     1.3867  1.4094  1.3081  1.2259  1.2960  1.3252  0.0661  \n",
      "Fit time          0.02    0.01    0.01    0.01    0.01    0.01    0.00    \n",
      "Test time         0.00    0.00    0.00    0.00    0.00    0.00    0.00    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x21a080c0ca0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise import SVD\n",
    "\n",
    "# Define the matrix factorization algorithm (e.g., SVD)\n",
    "mf_model = SVD()\n",
    "\n",
    "# Perform cross-validation on the training data\n",
    "cross_validate(mf_model, train_dataset, measures=['RMSE', 'MAE'], cv=5, verbose=True)\n",
    "\n",
    "# Train the matrix factorization model on the entire training data\n",
    "mf_model.fit(trainset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe36e81",
   "metadata": {},
   "source": [
    "# Content-Based Filtering Model Metrics Precision, f1 score, Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ded4f71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content-Based Filtering Model Metrics:\n",
      "Precision: 0.7032967032967034\n",
      "Recall: 0.23063063063063063\n",
      "F1 Score: 0.34735413839891455\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "# Define a threshold to convert ratings into classes (e.g., positive and negative)\n",
    "threshold = 3.5\n",
    "\n",
    "# Convert the continuous ratings into binary classes\n",
    "true_classes = [1 if rating >= threshold else 0 for rating in train_data['overall']]\n",
    "predicted_classes = [1 if item in similar_items else 0 for item in train_data['asin']]\n",
    "\n",
    "# Compute precision, recall, and F1 score for the content-based filtering model\n",
    "precision = precision_score(true_classes, predicted_classes)\n",
    "recall = recall_score(true_classes, predicted_classes)\n",
    "f1 = f1_score(true_classes, predicted_classes)\n",
    "\n",
    "print(\"Content-Based Filtering Model Metrics:\")\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc70266b",
   "metadata": {},
   "source": [
    "# Matrix Factorization Precision, f1 score, Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "819a9943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix Factorization Model Metrics:\n",
      "Precision: 0.7012987012987013\n",
      "Recall: 0.8244274809160306\n",
      "F1 Score: 0.7578947368421054\n"
     ]
    }
   ],
   "source": [
    "# Matrix Factorization Precision, f1 score, Recall\n",
    "\n",
    "# Generate predictions on the test set\n",
    "test_dataset = Dataset.load_from_df(test_data[['reviewerID', 'asin', 'overall']], reader)\n",
    "testset = test_dataset.build_full_trainset().build_testset()\n",
    "mf_predictions = mf_model.test(testset)\n",
    "\n",
    "# Convert ratings into classes based on a threshold\n",
    "threshold = 3.6\n",
    "true_classes = [1 if rating >= threshold else 0 for rating in test_data['overall']]\n",
    "predicted_classes = [1 if pred.est >= threshold else 0 for pred in mf_predictions]\n",
    "\n",
    "# Compute precision, recall, and F1 score for the matrix factorization model\n",
    "precision = precision_score(true_classes, predicted_classes)\n",
    "recall = recall_score(true_classes, predicted_classes)\n",
    "f1 = f1_score(true_classes, predicted_classes)\n",
    "\n",
    "# Print the evaluation results\n",
    "print(\"Matrix Factorization Model Metrics:\")\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3648a65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, render_template, request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4b7e0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Flask(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed0067fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      " * Restarting with watchdog (windowsapi)\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ihiba\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3468: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, render_template, request\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from surprise import Dataset, Reader, KNNBasic\n",
    "\n",
    "data = pd.read_csv(r'C:\\Users\\ihiba\\OneDrive\\Desktop\\recommendation_data.csv')\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a reader object to parse the data\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "\n",
    "# Load the data into the Surprise Dataset format\n",
    "train_dataset = Dataset.load_from_df(train_data[['reviewerID', 'asin', 'overall']], reader)\n",
    "\n",
    "# Create a TF-IDF vectorizer to convert text features into numerical vectors\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(train_data['reviewText'].values.astype('U'))\n",
    "\n",
    "# Compute cosine similarities between all items using the TF-IDF vectors\n",
    "item_similarities = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/')\n",
    "def home():\n",
    "    return render_template('recommendation.html')\n",
    "\n",
    "@app.route('/recommendations', methods=['GET'])\n",
    "def recommend_items():\n",
    "    item_id = request.args.get('asin')\n",
    "    top_n = int(request.args.get('top_n', 5))\n",
    "    similar_items = get_similar_items(item_id, top_n)\n",
    "    return render_template('recommendation.html', item_id=item_id, items=similar_items)\n",
    "\n",
    "def get_similar_items(item_id, top_n=5):\n",
    "    item_index = train_data[train_data['asin'] == item_id].index[0]\n",
    "    similar_indices = item_similarities[item_index].argsort()[::-1][1:top_n+1]\n",
    "    similar_items = train_data.iloc[similar_indices][['asin', 'overall', 'reviewText']]\n",
    "    return similar_items\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce047d2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
